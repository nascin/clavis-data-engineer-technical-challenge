# ==========================================
# CLAVIS DATA ENGINEER CHALLENGE
# Logstash Main Pipeline - Routes all data
# ==========================================

input {
  beats {
    port => 5044
  }
}

filter {
  # ==========================================
  # CRYPTO PRICES
  # ==========================================
  if [fields][pipeline] == "crypto-prices" {

    # Parse JSON from message field (NDJSON: one complete JSON per line)
    json {
      source => "message"
      skip_on_invalid_json => true
    }

    # Extract BRL quote data
    if [quotes][BRL] {
      ruby {
        code => "
          brl = event.get('[quotes][BRL]')
          if brl
            event.set('price_brl', brl['price'])
            event.set('volume_24h_brl', brl['volume_24h'])
            event.set('market_cap_brl', brl['market_cap'])
            event.set('percent_change_1h', brl['percent_change_1h'])
            event.set('percent_change_24h', brl['percent_change_24h'])
            event.set('percent_change_7d', brl['percent_change_7d'])
            event.set('percent_change_30d', brl['percent_change_30d'])
          end
        "
      }

      # Convert to numbers
      mutate {
        convert => {
          "price_brl" => "float"
          "volume_24h_brl" => "float"
          "market_cap_brl" => "float"
          "percent_change_1h" => "float"
          "percent_change_24h" => "float"
          "percent_change_7d" => "float"
          "percent_change_30d" => "float"
          "rank" => "integer"
          "circulating_supply" => "float"
          "total_supply" => "float"
          "max_supply" => "float"
        }
      }
    }

    # Add routing metadata
    mutate {
      add_field => {
        "[@metadata][target_index]" => "crypto-prices"
        "data_source" => "coinmarketcap"
        "data_type" => "crypto_prices"
      }
      remove_field => ["crypto_array", "message", "log", "host", "agent", "ecs", "input", "fields"]
    }

    # Timestamp already parsed from JSON - no additional parsing needed
  }

  # ==========================================
  # GLOBAL METRICS
  # ==========================================
  else if [fields][pipeline] == "crypto-global-metrics" {

    # Parse JSON from message field (NDJSON: one complete JSON per line)
    json {
      source => "message"
      skip_on_invalid_json => true
    }

    # Extract BRL quote data
    if [quotes][BRL] {
      ruby {
        code => "
          brl = event.get('[quotes][BRL]')
          if brl
            event.set('total_market_cap_brl', brl['total_market_cap'])
            event.set('total_volume_24h_brl', brl['total_volume_24h'])
            event.set('altcoin_volume_24h_brl', brl['altcoin_volume_24h'])
            event.set('altcoin_market_cap_brl', brl['altcoin_market_cap'])
          end
        "
      }

      # Convert to numbers
      mutate {
        convert => {
          "total_market_cap_brl" => "float"
          "total_volume_24h_brl" => "float"
          "altcoin_volume_24h_brl" => "float"
          "altcoin_market_cap_brl" => "float"
          "active_cryptocurrencies" => "integer"
          "active_exchanges" => "integer"
          "active_market_pairs" => "integer"
          "btc_dominance" => "float"
          "eth_dominance" => "float"
          "defi_volume_24h" => "float"
          "defi_market_cap" => "float"
          "stablecoin_volume_24h" => "float"
          "stablecoin_market_cap" => "float"
        }
      }
    }

    # Add routing metadata
    mutate {
      add_field => {
        "[@metadata][target_index]" => "crypto-global-metrics"
        "data_source" => "coinmarketcap"
        "data_type" => "global_metrics"
      }
      remove_field => ["message", "log", "host", "agent", "ecs", "input", "fields"]
    }

    # Timestamp already parsed from JSON - no additional parsing needed
  }

  # ==========================================
  # PIPELINE METRICS
  # ==========================================
  else if [fields][pipeline] == "pipeline-metrics" {

    # Parse JSON from message field (NDJSON: one complete JSON per line)
    json {
      source => "message"
      skip_on_invalid_json => true
    }

    # Parse execution duration
    if [execution_duration_seconds] {
      mutate {
        convert => { "execution_duration_seconds" => "float" }
      }
    }

    # Parse counts
    mutate {
      convert => {
        "records_extracted" => "integer"
        "records_processed" => "integer"
        "records_failed" => "integer"
        "api_calls_used" => "integer"
        "crypto_records" => "integer"
        "global_metrics_records" => "integer"
        "cryptocurrencies_monitored" => "integer"
        "fiat_currencies" => "integer"
      }
    }

    # Calculate success rate
    if [records_processed] and [records_extracted] {
      ruby {
        code => "
          processed = event.get('records_processed')
          extracted = event.get('records_extracted')
          if extracted && extracted > 0
            success_rate = (processed.to_f / extracted.to_f * 100).round(2)
            event.set('success_rate_percent', success_rate)
          end
        "
      }
    }

    # Add routing metadata
    mutate {
      add_field => {
        "[@metadata][target_index]" => "pipeline-metrics"
        "data_source" => "airflow"
        "data_type" => "execution_logs"
      }
      remove_field => ["message", "log", "host", "agent", "ecs", "input", "fields"]
    }

    # Timestamp already parsed from JSON - no additional parsing needed
  }

  # Drop unrecognized data
  else {
    drop { }
  }
}

output {
  # Route to appropriate index
  if [@metadata][target_index] == "crypto-prices" {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "crypto-prices-%{+YYYY.MM.dd}"
      manage_template => false
    }
  }
  else if [@metadata][target_index] == "crypto-global-metrics" {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "crypto-global-metrics-%{+YYYY.MM.dd}"
      manage_template => false
    }
  }
  else if [@metadata][target_index] == "pipeline-metrics" {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "pipeline-metrics-%{+YYYY.MM.dd}"
      manage_template => false
    }
  }

  # Debug (descomente se necessÃ¡rio)
  # stdout { codec => rubydebug { metadata => true } }
}